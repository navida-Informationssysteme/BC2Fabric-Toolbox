{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance SQL Views Installer\n",
    "\n",
    "This notebook fetches the latest SQL definition from GitHub and executes it against the specified SQL Analytics Endpoint.\n",
    "\n",
    "**GitHub Source:** [finance-sql-views.sql](https://github.com/navida-Informationssysteme/BC2Fabric-Toolbox/blob/main/Accelerators/Finance-Reporting/finance-sql-views.sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyodbc\n",
    "import struct\n",
    "import re\n",
    "\n",
    "# Try importing the modern notebookutils, fallback to mssparkutils if needed\n",
    "try:\n",
    "    from notebookutils import credentials\n",
    "except ImportError:\n",
    "    from mssparkutils import credentials\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Configuration\n",
    "# -------------------------------------------------------\n",
    "# URL to the raw SQL file on GitHub\n",
    "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/navida-Informationssysteme/BC2Fabric-Toolbox/main/Accelerators/Finance-Reporting/finance-sql-views.sql\"\n",
    "\n",
    "# SQL Endpoint and Database details\n",
    "SQL_ENDPOINT = \"ryxn3t66mqleblwe5fkgsvj3di-slpu2ietzspuxpjlkbn77ew3ua.datawarehouse.fabric.microsoft.com\"\n",
    "DATABASE_NAME = \"bc2fabric_mirror\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Fetch SQL Content\n",
    "# -------------------------------------------------------\n",
    "print(f\"Fetching SQL from: {GITHUB_RAW_URL}\")\n",
    "try:\n",
    "    response = requests.get(GITHUB_RAW_URL)\n",
    "    response.raise_for_status()\n",
    "    sql_content = response.text\n",
    "    print(\"SQL content fetched successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to fetch SQL file: {e}\")\n",
    "    raise\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Connect to SQL Endpoint\n",
    "# -------------------------------------------------------\n",
    "# Get Entra ID (AAD) token\n",
    "token = credentials.getToken(\"pbi\")\n",
    "token_bytes = token.encode(\"UTF-16LE\")\n",
    "token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\n",
    "SQL_COPT_SS_ACCESS_TOKEN = 1256 \n",
    "\n",
    "# Construct Connection String\n",
    "conn_str = (\n",
    "    f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
    "    f\"Server={SQL_ENDPOINT},1433;\"\n",
    "    f\"Database={DATABASE_NAME};\"\n",
    "    f\"Encrypt=yes;\"\n",
    "    f\"TrustServerCertificate=no;\"\n",
    "    f\"Connection Timeout=30;\"\n",
    ")\n",
    "\n",
    "print(f\"Connecting to {DATABASE_NAME}...\")\n",
    "\n",
    "try:\n",
    "    # Autocommit is often required for DDL statements in loops\n",
    "    with pyodbc.connect(conn_str, attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct}, autocommit=True) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # -------------------------------------------------------\n",
    "        # 3. Robust SQL Parsing\n",
    "        # -------------------------------------------------------\n",
    "        # Handles \"GO\", \"GO;\", case insensitivity, and surrounding whitespace\n",
    "        split_pattern = r'^\\s*GO\\s*;?\\s*$'\n",
    "        \n",
    "        statements = re.split(split_pattern, sql_content, flags=re.IGNORECASE | re.MULTILINE)\n",
    "        \n",
    "        # Filter out empty strings\n",
    "        statements = [stmt.strip() for stmt in statements if stmt.strip()]\n",
    "        \n",
    "        print(f\"Found {len(statements)} primary batches to execute.\")\n",
    "        \n",
    "        for i, stmt in enumerate(statements):\n",
    "            # -------------------------------------------------------\n",
    "            # 4. Sub-batch Splitting Logic (Schema + View Fix)\n",
    "            # -------------------------------------------------------\n",
    "            # T-SQL requires CREATE VIEW to be the first statement in a batch.\n",
    "            # If a file has \"CREATE SCHEMA ... CREATE VIEW\" without a GO, we split manually.\n",
    "            sub_statements = [stmt]\n",
    "            \n",
    "            if \"CREATE SCHEMA\" in stmt.upper() and \"CREATE OR ALTER VIEW\" in stmt.upper():\n",
    "                 # Lookahead split: Split right before \"CREATE OR ALTER VIEW\"\n",
    "                 sub_statements = re.split(r'(?=CREATE\\s+OR\\s+ALTER\\s+VIEW)', stmt, flags=re.IGNORECASE)\n",
    "\n",
    "            for sub_stmt in sub_statements:\n",
    "                clean_stmt = sub_stmt.strip()\n",
    "                if not clean_stmt: continue\n",
    "                \n",
    "                print(f\"Executing batch {i+1} part...\")\n",
    "                try:\n",
    "                    cursor.execute(clean_stmt)\n",
    "                except pyodbc.Error as e:\n",
    "                    print(f\"Error executing batch {i+1}:\")\n",
    "                    print(f\"Query start: {clean_stmt[:200]}...\") \n",
    "                    print(f\"Error details: {e}\")\n",
    "                    # Raising error ensures we don't leave the DB in a half-baked state silently\n",
    "                    raise \n",
    "\n",
    "        print(\"All views created successfully.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"An error occurred during the database operation.\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}